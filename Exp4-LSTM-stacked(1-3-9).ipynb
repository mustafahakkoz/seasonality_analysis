{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from the text file\n",
    "with open('./data/IBM.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    data = []\n",
    "    dates = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split(',')\n",
    "        date = parts[0]\n",
    "        if '1980-12-12' <= date <= '2022-07-22':\n",
    "            dates.append(date)\n",
    "            data.append(float(parts[4]))  # 'Close' column\n",
    "\n",
    "# Create a DataFrame from the loaded data\n",
    "df = pd.DataFrame({'Date': pd.to_datetime(dates), 'Value': data})\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Extract the values from the DataFrame\n",
    "signal = df['Value'].values\n",
    "signal = signal.reshape(-1, 1)\n",
    "\n",
    "# Define the training and testing data\n",
    "train_size = int(len(signal) * 0.8)\n",
    "train_data = signal[:train_size, :]\n",
    "test_data = signal[train_size:, :]\n",
    "\n",
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "def create_groups(dataset, window_size_1, window_size_2, window_size_3, timeslice, step):\n",
    "    X_data, y_data = [], []\n",
    "    index = 0\n",
    "    while index + (timeslice * window_size_3) < len(dataset):\n",
    "        i = 0\n",
    "        t1, t2, t3 = [], [], []\n",
    "        l1, l2, l3 = [], [], []\n",
    "        while i < timeslice* window_size_1:\n",
    "            current_slice = dataset[index + i:index + i + window_size_1, 0]\n",
    "            if not np.isnan(current_slice).all():\n",
    "                t1.append(np.mean(current_slice))\n",
    "                \n",
    "            i = i + window_size_1\n",
    "        l1.append(dataset[index +  timeslice*window_size_1])\n",
    "        i = 0   \n",
    "        while i < timeslice* window_size_2:\n",
    "            current_slice = dataset[index + i:index + i + window_size_2, 0]\n",
    "            if not np.isnan(current_slice).all():\n",
    "                t2.append(np.mean(current_slice))\n",
    "                \n",
    "            i = i + window_size_2\n",
    "        l2.append(dataset[index + timeslice*window_size_2])\n",
    "        i = 0   \n",
    "        while i < timeslice* window_size_3:\n",
    "            current_slice = dataset[index + i:index + i + window_size_3, 0]\n",
    "            if not np.isnan(current_slice).all():\n",
    "                t3.append(np.mean(current_slice))\n",
    "            \n",
    "            i = i + window_size_3\n",
    "        l3.append(dataset[index + timeslice*window_size_3])\n",
    "        X_data.append(np.concatenate([t1, t2, t3]))\n",
    "        y_data.append(np.concatenate([l3]))\n",
    "        index = index +step\n",
    "\n",
    "    return np.array(X_data), np.array(y_data)\n",
    "\n",
    "window_size_1 = 1\n",
    "window_size_2 = 3\n",
    "window_size_3 = 9\n",
    "timeslice = 4\n",
    "step = 1\n",
    "X_train, y_train = create_groups(train_data, window_size_1, window_size_2, window_size_3, timeslice, step)\n",
    "X_test, y_test = create_groups(test_data, window_size_1, window_size_2, window_size_3, timeslice, step)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03268669]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "66/66 [==============================] - 3s 22ms/step - loss: 0.0162 - val_loss: 0.0012\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0017 - val_loss: 8.8134e-04\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.0013 - val_loss: 8.6665e-04\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 8.8014e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x291dbfb80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the LSTM model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 2ms/step\n",
      "RMSE: 5.829913366149171\n",
      "MAPE: 3.1513523969415114\n",
      "MSE:  33.987889856804756\n",
      "MSLE:  0.0019353868755328366\n",
      "MAE:  4.222430059186883\n",
      "R-squared:  0.8922566906678941\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1]))\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Assuming y_pred and y_test are NumPy arrays\n",
    "# Note: For MAPE, make sure y_test does not contain zeros to avoid division by zero.\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# MAPE\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('MAPE:', mape)\n",
    "\n",
    "\n",
    "print('MSE: ', mse)\n",
    "print('MSLE: ', msle)\n",
    "print('MAE: ', mae)\n",
    "print('R-squared: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-3\n",
    "\n",
    "RMSE: 5.829913366149171\n",
    "MAPE: 3.1513523969415114\n",
    "MSE:  33.987889856804756\n",
    "MSLE:  0.0019353868755328366\n",
    "MAE:  4.222430059186883\n",
    "R-squared:  0.8922566906678941\n",
    "\n",
    "# 1-3-9\n",
    "\n",
    "RMSE: 10.743495846758746\n",
    "MAPE: 6.150518474732841\n",
    "MSE:  115.42270300932242\n",
    "MSLE:  0.006470582817612666\n",
    "MAE:  8.509658938709455\n",
    "R-squared:  0.6053778770352263\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "serkanTez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
